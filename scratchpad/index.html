<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title></title>
		<link href="/css/main.css" rel="stylesheet">
	</head>
	<body class='hack'>
		<nav>
			
			<a href="/"><span itemprop="name">[ Home ]</span></a>
			<a href="/projects"><span itemprop="name">[ Projects ]</span></a>
			<a href="/write_ups"><span itemprop="name">[ Write Ups ]</span></a>
			<a href="/scratchpad"><span itemprop="name">[ scratchpad ]</span></a>
			
		</nav>
		
		
	
		<div>
			<h1>wget spider</h1>
			<p><span id="continue-reading"></span>
<p><code>wget --mirror --convert-links --page-requisites --adjust-extension &lt;site-url&gt;</code></p>
<ul>
<li><strong>--mirror</strong>: make the download recursive</li>
<li><strong>--convert-links</strong>: convert links to work offline ex. <code>./</code> instead of <code>/</code></li>
<li><strong>--page-requisites</strong>: make sure to download js and css</li>
<li><strong>--adjust-extension</strong>: append missing extensions (mostly for html)</li>
</ul>
<h3 id="warc">WARC</h3>
<p>If I'm crawling a site for an offline backup I probably need a zim file. Wget can't output a zim file but it can output a warc file which can be converted to a zim file using <a href="https://github.com/openzim/warc2zim">warc2zim</a></p>
<ul>
<li><strong>--warc-file</strong>=filename: enables warc export, standard output will also happen</li>
</ul>
<h3 id="cross-domain">Cross domain</h3>
<ul>
<li><strong>--span-hosts</strong>: crawl cross domain links</li>
<li><strong>--domains</strong>: make sure you only crawl the domains you want to (don't want to accidentally crawl the whole internet)</li>
</ul>
</p>
		</div>
	
		<div>
			<h1>Netcat Webserver</h1>
			<p><span id="continue-reading"></span>
<p><code>while true; do echo -e "HTTP/1.1 200 OK\n\n" $(cat index.html) | nc -lp 8080 -q 1; done</code></p>
<ul>
<li>"HTTP/1.1 200 OK\n\n" can be put in the html file. Just be sure to use <code>^M^M</code> instead of the literal <code>\n\n</code></li>
</ul>
</p>
		</div>
	
		<div>
			<h1>Strip everything except ascii from Text files</h1>
			<p><span id="continue-reading"></span>
<p>A really quick way of doing this is to use <code>strings</code>. However this will strip whitespace characters.</p>
<p>If you need whitespace characters intact you can use this:</p>
<p><code>cat &lt;file&gt; | tr -d "[:cntrl:]" | iconv -c -f utf-8 -t ascii -</code></p>
</p>
		</div>
	
		<div>
			<h1>Python One-Liners</h1>
			<p><span id="continue-reading"></span>
<p>Takes a list of urls and formats them in markdown
<code>python -c "import sys; from urllib.parse import urlsplit; print(''.join([f\"[{urlsplit(line.strip()).path.lstrip('/')}]({line.strip()})\n\" for line in sys.stdin]))"</code></p>
</p>
		</div>
	
	
		
	</body>
</html>
